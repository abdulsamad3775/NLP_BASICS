{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f2b94bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0adc79f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\abdulsamad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5993b790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 2)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bbc_text_cls.csv')\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20709ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate word2idx\n",
    "# convert documents into sequences of ints / ids / indices\n",
    "idx = 0\n",
    "word2idx = {}\n",
    "tokenized_docs = []\n",
    "for doc in df['text']:\n",
    "  words = word_tokenize(doc.lower())\n",
    "  doc_as_int = []\n",
    "  for word in words:\n",
    "    if word not in word2idx:\n",
    "      word2idx[word] = idx\n",
    "      idx += 1\n",
    "\n",
    "    # save for later\n",
    "    doc_as_int.append(word2idx[word])\n",
    "  tokenized_docs.append(doc_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0f6ad7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #------checkings-------\n",
    "# len(doc_as_int)\n",
    "# # doc_as_int\n",
    "# # len(word2idx)\n",
    "# len(tokenized_docs)\n",
    "\n",
    "# for doc in tokenized_docs:\n",
    "#     print(len(doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0326b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse mapping\n",
    "# if you do it smarter you can store it as a list\n",
    "idx2word = {v:k for k, v in word2idx.items()}\n",
    "# idx2word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "12340eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34762"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of documents\n",
    "N = len(df['text'])\n",
    "\n",
    "# number of words\n",
    "V = len(word2idx)\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "86c701f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 34762)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate term-frequency matrix\n",
    "# note: could have also used count vectorizer\n",
    "tf = np.zeros((N, V))\n",
    "tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "37898fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate term-frequency counts\n",
    "for i, doc_as_int in enumerate(tokenized_docs):\n",
    "  for j in doc_as_int:\n",
    "    tf[i, j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c523d1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 34762)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "34eabae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34762,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute IDF\n",
    "document_freq = np.sum(tf > 0, axis=0) # document frequency (shape = (V,))\n",
    "idf = np.log(N / document_freq)\n",
    "idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a6b9c07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf > 0\n",
    "# np.sum(tf > 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0e5882f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 34762)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute TF-IDF\n",
    "tf_idf = tf * idf\n",
    "tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1e53bb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: sport\n",
      "Text: Athens memories soar above lows\n",
      "Top 5 terms:\n",
      "paula\n",
      "athens\n",
      "1500m\n",
      "her\n",
      "kelly\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# pick a random document, show the top 5 terms (in terms of tf_idf score)\n",
    "i = np.random.choice(N)\n",
    "row = df.iloc[i]\n",
    "print(\"Label:\", row['labels'])\n",
    "print(\"Text:\", row['text'].split(\"\\n\", 1)[0])\n",
    "print(\"Top 5 terms:\")\n",
    "\n",
    "scores = tf_idf[i] \n",
    "indices = (-scores).argsort()\n",
    "\n",
    "for j in indices[:5]:\n",
    "  print(idx2word[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2192b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: use CountVectorizer to form the counts instead\n",
    "\n",
    "# Exercise (hard): use Scipy's csr_matrix instead\n",
    "# You cannot use X[i, j] += 1 here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
